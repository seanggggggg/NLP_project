{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quora Question Pair"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The question origins from the kaggle competition: https://www.kaggle.com/c/quora-question-pairs\n",
    "The target of the project is that given a pair of questions, we need to determine if they are duplicated questions or not. The two questions are defined to be duplicated if they can be solved by the same solution. The difficulties of the questions are: \n",
    "1. Two sentences are not guaranteed to be duplicated even if one sentence is almost a copy of another one.\n",
    "2. The same question can be presented as different forms. \n",
    "3. Even though the two questions are not semantically equivalent, they may still be solved by the same answer. \n",
    "Because of the first and the second difficulty, we need to find ways to identify if the two sentences are semantically equivalent. However, the third difficulty determines that the above is not enough and we need to feed all features into the ML model for prediction. \n",
    "\n",
    "Reference: \n",
    "1. https://www.aclweb.org/anthology/K15-1013\n",
    "2. https://cs.stanford.edu/~quocle/paragraph_vector.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read and concatenate train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['qid1'].astype(int, copy=False)\n",
    "train['qid2'].astype(int, copy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_size: 404290\n",
      "test_size: 2345796\n"
     ]
    }
   ],
   "source": [
    "train_size = train.shape[0]\n",
    "test_size = test.shape[0]\n",
    "print(\"train_size: %d\" % train_size) \n",
    "print(\"test_size: %d\" % test_size) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/site-packages/ipykernel_launcher.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>test_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id is_duplicate qid1 qid2  \\\n",
       "0  0            0    1    2   \n",
       "1  1            0    3    4   \n",
       "2  2            0    5    6   \n",
       "3  3            0    7    8   \n",
       "4  4            0    9   10   \n",
       "\n",
       "                                           question1  \\\n",
       "0  What is the step by step guide to invest in sh...   \n",
       "1  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2  How can I increase the speed of my internet co...   \n",
       "3  Why am I mentally very lonely? How can I solve...   \n",
       "4  Which one dissolve in water quikly sugar, salt...   \n",
       "\n",
       "                                           question2 test_id  \n",
       "0  What is the step by step guide to invest in sh...          \n",
       "1  What would happen if the Indian government sto...          \n",
       "2  How can Internet speed be increased by hacking...          \n",
       "3  Find the remainder when [math]23^{24}[/math] i...          \n",
       "4            Which fish would survive in salt water?          "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.concat([train,test],ignore_index=True).fillna(\"\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenize the document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_texts = pd.concat([data['question1'][:train_size], data['question2'][:train_size], data['question1'][train_size:], data['question2'][train_size:]], ignore_index=True)\n",
    "raw_texts = raw_texts.astype(str).str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_train_size = 2 * train_size\n",
    "text_size = test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tk = Tokenizer(lower = True)\n",
    "tk.fit_on_texts(raw_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tk_q1 = tk.texts_to_sequences(raw_texts[:train_size])\n",
    "train_tk_q2 = tk.texts_to_sequences(raw_texts[train_size:text_train_size])\n",
    "test_tk_q1 = tk.texts_to_sequences(raw_texts[text_train_size:text_train_size+text_size])\n",
    "test_tk_q2 = tk.texts_to_sequences(raw_texts[text_train_size+text_size:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tk_q1 = train_tk_q1 + test_tk_q1\n",
    "tk_q2 = train_tk_q2 + test_tk_q2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similarity features (copy)\n",
    "Functions that generate features help to determine if one sentence is a copy of another sentence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of shared words\n",
    "def num_codes(tk):\n",
    "    ans = []\n",
    "    for row in range(len(tk)):\n",
    "        ans.append(len(tk[row]))\n",
    "    return ans\n",
    "\n",
    "\n",
    "\n",
    "# number of unique words     \n",
    "def num_unique_codes(tk):\n",
    "    ans = []\n",
    "    for row in range(len(tk)):\n",
    "        ans.append(len(set(tk[row])))\n",
    "    return list(ans)\n",
    "\n",
    "\n",
    "# number of letters\n",
    "def num_letters(tk, tkcode):\n",
    "    ans = []\n",
    "    index_word = tk.index_word\n",
    "    for row in range(len(tkcode)):\n",
    "        num = 0\n",
    "        for windex in tkcode[row]:\n",
    "            num += len(index_word[windex])\n",
    "        ans.append(num)\n",
    "    return ans\n",
    "\n",
    "\n",
    "# Jaccard similarity\n",
    "def Jaccard(tk_q1, tk_q2):\n",
    "    ans = []\n",
    "    for row in range(len(tk_q1)):\n",
    "        q1 = tk_q1[row]\n",
    "        q2 = tk_q2[row]\n",
    "        inter1 = len([c for c in q1 if c in q2])\n",
    "        inter2 = len([c for c in q2 if c in q1])\n",
    "        inter = inter1+inter2\n",
    "        union = len(q1)+len(q2)\n",
    "        if union == 0:\n",
    "            ans.append(1)\n",
    "        else:\n",
    "            ans.append(inter/union*100)\n",
    "    return ans\n",
    "\n",
    "\n",
    "# Jaccard similarity with 2-shingles\n",
    "def Jaccard_2_shingles(tk_q1, tk_q2):\n",
    "    ans = []\n",
    "    for row in range(len(tk_q1)):\n",
    "        q1 = tk_q1[row]\n",
    "        q2 = tk_q2[row]\n",
    "        q1_2_shingles = []\n",
    "        for i in range(len(q1)-1):\n",
    "            q1_2_shingles.append((q1[i], q1[i+1]))\n",
    "        q2_2_shingles = []\n",
    "        for i in range(len(q2)-1):\n",
    "            q2_2_shingles.append((q2[i], q2[i+1]))\n",
    "        inter1 = len([c for c in q1_2_shingles if c in q2_2_shingles])\n",
    "        inter2 = len([c for c in q2_2_shingles if c in q1_2_shingles])\n",
    "        inter = inter1+inter2\n",
    "        union = len(q1_2_shingles)+len(q2_2_shingles)\n",
    "        if union == 0:\n",
    "            ans.append(1)\n",
    "        else:\n",
    "            ans.append(inter/union*100)\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['question1_num_codes'] = num_codes(tk_q1)\n",
    "data['question2_num_codes'] = num_codes(tk_q2)\n",
    "#data['question1_num_words'] = num_words(data['question1'])\n",
    "#data['question2_num_words'] = num_words(data['question2'])\n",
    "data['question1_num_unique_words'] = num_unique_words(tk_q1)\n",
    "data['question2_num_unique_words'] = num_unique_words(tk_q2)\n",
    "data['question1_words_vs_unique'] = data['question1_num_unique_words'] / data['question1_num_words'] * 100\n",
    "data['question2_words_vs_unique'] = data['question2_num_unique_words'] / data['question2_num_words'] * 100\n",
    "data['question1_num_letter1'] = num_letters(tk, tk_q1)\n",
    "data['question2_num_letter1'] = num_letters(tk, tk_q2)\n",
    "data['q1_q2_nw_ratio'] = data['question1_num_words'] / data['question2_num_words'] * 100\n",
    "data['q1_q2_nw_unique_ratio'] = data['question1_num_unique_words'] / data['question2_num_unique_words'] * 100\n",
    "data['Jaccard'] = Jaccard(tk_q1, tk_q2)\n",
    "data['Jaccard_2_singles'] = Jaccard_2_shingles(tk_q1, tk_q2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentence embedding\n",
    "Our focus for the project is on the creation of sentence embedding and generate similarity score from the vector presentation of the sentences. Two methods have been studied and used: \n",
    "1. https://cs.stanford.edu/~quocle/paragraph_vector.pdf. doc2vec library can be used to generate sentence embedding\n",
    "2. https://www.aclweb.org/anthology/K15-1013. Implemented by Shu Hong."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## doc2vec\n",
    "Since the method is unsupervised learning and test data is much more than training data, we use train data and test data for learning the sentence embedding. We can expect further improvement if we introduce all the questions from the quora platform. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = {}\n",
    "qid = 537934\n",
    "for index, drow in data.iterrows():\n",
    "    if index < train_size:\n",
    "        docs[tuple(drow['question1'].lower().split())] = drow['qid1']\n",
    "        docs[tuple(drow['question2'].lower().split())] = drow['qid2']\n",
    "    else:\n",
    "        doc = tuple(drow['question1'].lower().split())\n",
    "        if doc in docs:\n",
    "            data.at[index, 'qid1'] = docs[doc]\n",
    "        else:\n",
    "            data.at[index, 'qid1'] = qid\n",
    "            docs[doc] = qid\n",
    "            qid += 1\n",
    "        doc = tuple(drow['question2'].lower().split())\n",
    "        if doc in docs:\n",
    "            data.at[index, 'qid2'] = docs[doc]\n",
    "        else:\n",
    "            data.at[index, 'qid2'] = qid\n",
    "            docs[doc] = qid\n",
    "            qid += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import utils\n",
    "from gensim.models.doc2vec import LabeledSentence\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from gensim.models import Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tags is used to distinguish among sentences\n",
    "# however, tags or integer index can be used to get sentence vectors \n",
    "labeled_questions = []\n",
    "for index, drow in data.iterrows():\n",
    "    labeled_questions.append(TaggedDocument(str(drow['question1']).lower().split(), [str(drow['qid1'])]))\n",
    "    labeled_questions.append(TaggedDocument(str(drow['question2']).lower().split(), [str(drow['qid2'])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Doc2Vec(dm = 1, min_count=1, window=10, vector_size=150, negative=10 ,dbow_words=1,hs=1,workers=-1)\n",
    "model.build_vocab(labeled_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #1 is complete.\n",
      "Epoch #2 is complete.\n",
      "Epoch #3 is complete.\n",
      "Epoch #4 is complete.\n",
      "Epoch #5 is complete.\n",
      "Epoch #6 is complete.\n",
      "Epoch #7 is complete.\n",
      "Epoch #8 is complete.\n",
      "Epoch #9 is complete.\n",
      "Epoch #10 is complete.\n",
      "Epoch #11 is complete.\n",
      "Epoch #12 is complete.\n",
      "Epoch #13 is complete.\n",
      "Epoch #14 is complete.\n",
      "Epoch #15 is complete.\n",
      "Epoch #16 is complete.\n",
      "Epoch #17 is complete.\n",
      "Epoch #18 is complete.\n",
      "Epoch #19 is complete.\n",
      "Epoch #20 is complete.\n",
      "Epoch #21 is complete.\n",
      "Epoch #22 is complete.\n",
      "Epoch #23 is complete.\n",
      "Epoch #24 is complete.\n",
      "Epoch #25 is complete.\n",
      "Epoch #26 is complete.\n",
      "Epoch #27 is complete.\n",
      "Epoch #28 is complete.\n",
      "Epoch #29 is complete.\n",
      "Epoch #30 is complete.\n",
      "Epoch #31 is complete.\n",
      "Epoch #32 is complete.\n",
      "Epoch #33 is complete.\n",
      "Epoch #34 is complete.\n",
      "Epoch #35 is complete.\n",
      "Epoch #36 is complete.\n",
      "Epoch #37 is complete.\n",
      "Epoch #38 is complete.\n",
      "Epoch #39 is complete.\n",
      "Epoch #40 is complete.\n",
      "Epoch #41 is complete.\n",
      "Epoch #42 is complete.\n",
      "Epoch #43 is complete.\n",
      "Epoch #44 is complete.\n",
      "Epoch #45 is complete.\n",
      "Epoch #46 is complete.\n",
      "Epoch #47 is complete.\n",
      "Epoch #48 is complete.\n",
      "Epoch #49 is complete.\n",
      "Epoch #50 is complete.\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(50):\n",
    "    model.train(labeled_questions,epochs=model.epochs,total_examples=model.corpus_count)\n",
    "    print(\"Epoch #{} is complete.\".format(epoch+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for index, drow in data.iterrows():\n",
    "    s1 = str(drow['question1'])\n",
    "    s2 = str(drow['question2'])\n",
    "    if len(s1) == 0 or len(s2) == 0:\n",
    "        if len(s1) == len(s2):\n",
    "            score = 1\n",
    "        else:\n",
    "            score = 0\n",
    "    else:\n",
    "        score = model.docvecs.similarity(str(drow['qid1']), str(drow['qid2']))\n",
    "    scores.append(score)\n",
    "data['sent_similarity'] = scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get word embedding and sentence embedding features\n",
    "The word embedding and the sentence embedding are also used as features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_feature_vec(doc, model, word_set):\n",
    "    feature_vec = np.zeros((model.vector_size,))\n",
    "    nwords = 0\n",
    "    for word in doc:\n",
    "        if word in word_set:\n",
    "            nwords += 1\n",
    "            feature_vec = np.add(feature_vec, model[word])\n",
    "    if nwords > 0:\n",
    "        feature_vec = np.divide(feature_vec, nwords)\n",
    "    return feature_vec\n",
    "\n",
    "\n",
    "def get_avg_feature_vecs(docs, model, word_set):\n",
    "    counter = 0\n",
    "    feature_vecs = np.zeros((len(docs), model.vector_size))\n",
    "    for doc in docs:\n",
    "        feature_vecs[counter] = make_feature_vec(doc, model, word_set)\n",
    "        counter += 1\n",
    "    return feature_vecs\n",
    "\n",
    "\n",
    "def get_doc_vecs(data, tag_name, model):\n",
    "    counter = 0\n",
    "    question = ''\n",
    "    if tag_name == 'qid1':\n",
    "        question = 'question1'\n",
    "    else:\n",
    "        question = 'question2'\n",
    "    docs = data[question]\n",
    "    doc_vecs = np.zeros((len(docs), model.vector_size))\n",
    "    for index, doc in enumerate(docs):\n",
    "        doc_vecs[counter] = model.docvecs[str(data[tag_name][index])]\n",
    "        counter += 1\n",
    "    return doc_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_set = model.wv.vocab\n",
    "word_emb_q1 = get_avg_feature_vecs(data['question1'], model, word_set)\n",
    "word_emb_q2 = get_avg_feature_vecs(data['question2'], model, word_set)\n",
    "word_emb = np.hstack([word_emb_q1, word_emb_q2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_emb_q1 = get_doc_vecs(data, 'qid1', model)\n",
    "doc_emb_q2 = get_doc_vecs(data, 'qid2', model)\n",
    "doc_emb = np.hstack([doc_emb_q1, doc_emb_q2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "features = ['question1_num_codes', 'question1_num_words', 'question1_num_unique_words', \n",
    "            'question1_words_vs_unique', 'question1_num_letter1', 'question2_num_codes', \n",
    "            'question2_num_words', 'question2_num_unique_words', \n",
    "            'question2_words_vs_unique', 'question2_num_letter1', \n",
    "            'q1_q2_nw_ratio', 'q1_q2_nw_unique_ratio', 'Jaccard', 'Jaccard_2_singles','sent_similarity']\n",
    "'''\n",
    "features = ['question1_num_codes', 'question1_num_words', 'question1_num_unique_words', \n",
    "            'question1_words_vs_unique', 'question1_num_letter1', 'question2_num_codes', \n",
    "            'question2_num_words', 'question2_num_unique_words', \n",
    "            'question2_words_vs_unique', 'question2_num_letter1', \n",
    "            'q1_q2_nw_ratio', 'q1_q2_nw_unique_ratio', 'Jaccard', 'Jaccard_2_singles','sent_similarity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.hstack([data[features].values,word_emb,doc_emb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# restore the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a = len(data)//2\n",
    "#pickle.dump(data1[:a], open('data_03.pkl', 'wb'), protocol=4)\n",
    "#pickle.dump(data1[a:], open('data_04.pkl', 'wb'), protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_1 = pickle.load(open('data_03.pkl', 'rb'))\n",
    "#data_2 = pickle.load(open('data_04.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data = np.vstack([data_1, data_2])\n",
    "#gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our implementation of the supervised learning based sentence embedding is in Word2Vec_Dup_Detection.ipynb file. The method is implemented by Shu Hong. We only use the similarities score as a feature. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1 = pd.read_csv('sh_similarity_train.csv')\n",
    "test1 = pd.read_csv('sh_similarity.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = pd.concat([train1, test1], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNum(s):\n",
    "    return s.replace('[[', '').replace(']]', '')\n",
    "\n",
    "\n",
    "sim = sim['similarity'].apply(getNum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = np.zeros((data.shape[0], data.shape[1]+1))\n",
    "data1[:,:-1] = data\n",
    "data1[:,-1] = sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = data1[:train_size]\n",
    "train_y = train['is_duplicate']\n",
    "test_x = data1[train_size:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree models\n",
    "lightGBM and XGboost are used for prediction. lightGBM can have better result and can obtain a logloss of 0.150058. The score can be further improved if we do model tuning and stacking. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_params = dict()\n",
    "lgb_params['objective'] = 'binary'\n",
    "lgb_params['learning_rate'] = 0.1\n",
    "lgb_params['num_leaves'] = 63\n",
    "lgb_params['max_depth'] = 15\n",
    "lgb_params['min_gain_to_split '] = 0.1\n",
    "#lgb_params['subsample'] = 0.7\n",
    "lgb_params['colsample_bytree'] = 0.7\n",
    "lgb_params['min_sum_hessian_in_leaf'] = 0.001\n",
    "#lgb_params[\"boosting\"] = 'dart'\n",
    "#lgb_params['lambda_l1'] = 0.01 \n",
    "lgb_params['seed']=42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lgb_cv = lgb.cv(lgb_params,\n",
    "                lgb.Dataset(train_x,\n",
    "                            label=train_y\n",
    "                            ),\n",
    "                num_boost_round=20000,\n",
    "                nfold=5,\n",
    "                stratified=True,\n",
    "                shuffle=True,\n",
    "                early_stopping_rounds=50,\n",
    "                seed=42,\n",
    "                verbose_eval=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best iteration: 91, best score: 0.150058\n"
     ]
    }
   ],
   "source": [
    "best_score = min(lgb_cv['binary_logloss-mean'])\n",
    "best_iteration = len(lgb_cv['binary_logloss-mean'])\n",
    "print ('Best iteration: %d, best score: %f' % (best_iteration, best_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params = {}\n",
    "xgb_params[\"objective\"] = \"binary:logistic\"\n",
    "xgb_params[\"eta\"] = 0.02\n",
    "xgb_params[\"seed\"] = 1234\n",
    "xgb_params[\"max_depth\"] = 15\n",
    "xgb_params[\"metric\"] = 'logloss'\n",
    "xgb_params['silent'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-logloss:0.676052+3.32e-05\ttest-logloss:0.676879+2.51762e-05\n",
      "[10]\ttrain-logloss:0.535931+0.000138905\ttest-logloss:0.544239+0.000205403\n",
      "[20]\ttrain-logloss:0.435226+0.000240436\ttest-logloss:0.450451+0.000340138\n",
      "[30]\ttrain-logloss:0.360004+0.000293356\ttest-logloss:0.381689+0.000421217\n",
      "[40]\ttrain-logloss:0.302277+0.000281019\ttest-logloss:0.330028+0.000504163\n",
      "[50]\ttrain-logloss:0.256867+0.000272261\ttest-logloss:0.290615+0.000591839\n",
      "[60]\ttrain-logloss:0.220614+0.000316419\ttest-logloss:0.260243+0.000618138\n",
      "[70]\ttrain-logloss:0.191413+0.000383474\ttest-logloss:0.236593+0.000662395\n",
      "[80]\ttrain-logloss:0.167605+0.000440586\ttest-logloss:0.218111+0.000717293\n",
      "[90]\ttrain-logloss:0.147908+0.000330174\ttest-logloss:0.203617+0.00077036\n",
      "[99]\ttrain-logloss:0.132921+0.000436975\ttest-logloss:0.193238+0.000812791\n",
      ", best_score: 0.193238, best_iteration: 100\n"
     ]
    }
   ],
   "source": [
    "xgb_cv = xgb.cv(xgb_params,\n",
    "    xgb.DMatrix(train_x,\n",
    "    label=train_y\n",
    "    ),\n",
    "    num_boost_round=100,\n",
    "    nfold=5,\n",
    "    metrics='logloss',\n",
    "    early_stopping_rounds=50,\n",
    "    verbose_eval=10)\n",
    "best_score = xgb_cv['test-%s-mean' % ('logloss')].min()\n",
    "best_iteration = len(xgb_cv)\n",
    "print (', best_score: %f, best_iteration: %d' % (best_score, best_iteration))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "x_train, x_dev, y_train, y_dev = train_test_split(train_x, train_y)\n",
    "train_data = lgb.Dataset(x_train, label=y_train, categorical_feature=[0,1])\n",
    "test_data = lgb.Dataset(x_dev, label=y_dev, categorical_feature=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/site-packages/lightgbm/basic.py:1184: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "/usr/lib/python3.6/site-packages/lightgbm/basic.py:742: UserWarning: categorical_feature in param dict is overridden.\n",
      "  warnings.warn('categorical_feature in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.152377\n",
      "Early stopping, best iteration is:\n",
      "[89]\tvalid_0's binary_logloss: 0.152092\n"
     ]
    }
   ],
   "source": [
    "model = lgb.train(lgb_params, train_data, valid_sets=test_data, num_boost_round=20000, early_stopping_rounds=50, verbose_eval=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.DataFrame()\n",
    "sub['test_id'] = test['test_id']\n",
    "sub['is_duplicate'] = y_pred\n",
    "sub.to_csv('submit.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
